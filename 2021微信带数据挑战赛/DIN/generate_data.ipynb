{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         userid  feedid  date_  device  read_comment  comment  like  \\\n",
      "0             8   71474      1       1             0        0     1   \n",
      "1             8   73916      1       1             0        0     0   \n",
      "2             8   50282      1       1             0        0     0   \n",
      "3             8   11391      1       1             0        0     1   \n",
      "4             8   27349      1       1             0        0     0   \n",
      "...         ...     ...    ...     ...           ...      ...   ...   \n",
      "6677724  250236   72813     12       2             0        0     0   \n",
      "6677725  250236   52019     12       2             0        0     0   \n",
      "6677726  250236   51045     12       2             0        0     0   \n",
      "6677727  250236   46881     12       2             0        0     0   \n",
      "6677728  250236   53804     12       2             1        0     0   \n",
      "\n",
      "         click_avatar    play  \n",
      "0                   0     500  \n",
      "1                   0     250  \n",
      "2                   0     750  \n",
      "3                   0    3750  \n",
      "4                   0     250  \n",
      "...               ...     ...  \n",
      "6677724             0    6369  \n",
      "6677725             0   13212  \n",
      "6677726             0       0  \n",
      "6677727             0       0  \n",
      "6677728             0  160560  \n",
      "\n",
      "[6677729 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_csv(\"my_data/pos_user_data.csv\", header=0, index_col=None)\n",
    "print(user_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.mkdir(\"my_data/data_14/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "recommend_col = ['userid', 'feedid', 'device']\n",
    "target_col = ['read_comment', 'comment', 'like', 'click_avatar']\n",
    "history_col = ['userid', 'feedid', 'read_comment', 'comment', 'like', 'click_avatar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_recommend = pd.DataFrame(columns=recommend_col)\n",
    "train_target = pd.DataFrame(columns=target_col)\n",
    "train_history = pd.DataFrame(columns=history_col)\n",
    "test_recommend = pd.DataFrame(columns=recommend_col)\n",
    "test_target = pd.DataFrame(columns=target_col)\n",
    "test_history = pd.DataFrame(columns=history_col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "user_id = user_data['userid'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for u in user_id:\n",
    "    temp = user_data[user_data['userid'] == u]\n",
    "    date = temp['date_'].unique()\n",
    "    if len(date) >= 3:\n",
    "        train_recommend = train_recommend.append(temp[temp['date_'] == date[-1]][train_recommend.columns])\n",
    "        test_recommend = test_recommend.append(temp[temp['date_'] == date[-1]][test_recommend.columns])\n",
    "        train_target = train_target.append(temp[temp['date_'] == date[-1]][train_target.columns])\n",
    "        test_target = test_target.append(temp[temp['date_'] == date[-1]][test_target.columns])\n",
    "        train_history = train_history.append(temp[temp['date_'] != date[-1]][train_history.columns])\n",
    "        test_history = test_history.append(temp[temp['date_'] != date[-1]][test_history.columns])\n",
    "    elif len(date) == 2:\n",
    "        train_recommend = train_recommend.append(temp[temp['date_'] == date[-1]][train_recommend.columns])\n",
    "        train_target = train_target.append(temp[temp['date_'] == date[-1]][train_target.columns])\n",
    "        train_history = train_history.append(temp[temp['date_'] != date[-2]][train_history.columns])\n",
    "    else:\n",
    "        if len(temp) < 2:\n",
    "            continue\n",
    "        else:\n",
    "            train_recommend = train_recommend.append(temp[-1: ][recommend_col])\n",
    "            train_target = train_target.append(temp[-1: ][target_col])\n",
    "            train_history = train_history.append(temp[ :-1][history_col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_recommend.to_csv(\"my_data/train/train_recommend.csv\")\n",
    "train_history.to_csv(\"my_data/train/train_history.csv\")\n",
    "train_target.to_csv(\"my_data/train/train_target.csv\")\n",
    "test_recommend.to_csv(\"my_data/test/test_recommend.csv\")\n",
    "test_history.to_csv(\"my_data/test/test_history.csv\")\n",
    "test_target.to_csv(\"my_data/test/test_target.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pandas as pd\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "my_info = pd.read_csv(\"my_data/my_info.csv\", header=0, index_col=None)\n",
    "my_info['manual_tag_list'] = my_info['manual_tag_list'].fillna(' ')\n",
    "tag_data = my_info['manual_tag_list'].values\n",
    "tag_token = preprocessing.TextVectorization(output_mode='binary')\n",
    "tag_token.adapt(tag_data)\n",
    "tag_vocabulary = tag_token.get_vocabulary()\n",
    "print(len(tag_vocabulary))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "my_info['manual_tag_list'] = my_info['manual_tag_list'].apply(lambda x: np.array(tag_token(x)).sum(axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_info.to_csv(\"my_data/my_info_gene.csv\", index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "history_data = pd.read_csv(\"my_data/train_14/train_history.csv\", header=0, index_col=0)\n",
    "\n",
    "i_history = pd.DataFrame(columns=history_data.columns)\n",
    "dis_history = pd.DataFrame(columns=['userid', 'feedid'])\n",
    "\n",
    "users = history_data['userid'].unique()\n",
    "history_data = history_data.groupby(by=['userid'])\n",
    "for u in users:\n",
    "    temp = history_data.get_group(u)\n",
    "    i_history = i_history.append(temp[(temp['like'] == 1) | (temp['comment'] == 1) | (temp['read_comment'] == 1) | (temp['click_avatar'] == 1)])\n",
    "    dis_history = dis_history.append(temp[(temp['like'] == 0) & (temp['comment'] == 0) & (temp['read_comment'] == 0) & (temp['click_avatar'] == 0)][['userid', 'feedid']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "gene = pd.read_csv(\"my_data/train_14/my_info_gene.csv\", header=0, index_col=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def convert_emb(x):\n",
    "    return np.array(x.replace('[', '').replace(']', '').split(','), dtype=np.float)\n",
    "\n",
    "def convert_tag(x):\n",
    "    return np.array(x.replace('[', '').replace(']', '').replace('\\n', '').split('. '), dtype=np.float)\n",
    "\n",
    "emb = gene.values[:, -2]\n",
    "tag = gene.values[:, -1]\n",
    "emb = np.array(list(map(convert_emb, emb)))\n",
    "tag = np.array(list(map(convert_tag, tag)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "gemb = np.average(emb, axis=0)\n",
    "np.save('general_feed_emd.npy', np.average(emb, axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "recom = pd.read_csv(\"my_data/train_14/train_recommend.csv\", header=0, index_col=None)\n",
    "target = pd.read_csv(\"my_data/train_14/train_target.csv\", header=0, index_col=None)\n",
    "\n",
    "\n",
    "all_recom = pd.concat([recom.reset_index(drop=True), target.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "temp = pd.DataFrame(columns=all_recom.columns)\n",
    "temp = temp.append(all_recom[(all_recom['like'] == 1) | (all_recom['forward'] == 1) | (all_recom['read_comment'] == 1) | (all_recom['click_avatar'] == 1)])\n",
    "\n",
    "temp = temp.sample(frac=1)\n",
    "temp_1 = temp[recom.columns]\n",
    "tar_1= temp[target.columns]\n",
    "\n",
    "temp_1.to_csv(\"my_data/train_14/train_recommend_true.csv\", index=None)\n",
    "tar_1.to_csv(\"my_data/train_14/train_target_true.csv\", index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}