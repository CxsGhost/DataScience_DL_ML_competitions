{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'input:0' shape=(3, 3) dtype=int32, numpy=\n",
      "array([[1, 1, 1],\n",
      "       [1, 1, 1],\n",
      "       [1, 1, 1]])>\n",
      "<tf.Variable 'input:0' shape=(3, 3) dtype=int32, numpy=\n",
      "array([[1, 1, 1],\n",
      "       [1, 1, 1],\n",
      "       [1, 1, 1]])>\n",
      "tf.Tensor(\n",
      "[[ 0.9060266  -0.01674981  0.2985723   0.33688113]\n",
      " [ 0.9060266  -0.01674981  0.2985723   0.33688113]\n",
      " [ 0.9060266  -0.01674981  0.2985723   0.33688113]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 可以直接在seq中给予层的列表，以及指定模型的名称(keras中绝大多数对象（层）都是有名称的）\n",
    "\n",
    "model = keras.models.Sequential(\n",
    "    layers=[\n",
    "            keras.layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "            keras.layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "            keras.layers.Dense(4, name=\"layer3\"),\n",
    "           ],\n",
    "    name='my_seq_model'\n",
    "                                )\n",
    "\n",
    "x = keras.backend.ones((3, 3), dtype='int32', name='input')\n",
    "print(x)\n",
    "y = model(x)\n",
    "\n",
    "\n",
    "# 以上这种等价于\n",
    "\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "x_1 = tf.ones((3, 3))\n",
    "print(x)\n",
    "y_1 = layer3(layer2(layer1(x)))\n",
    "print(y_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Dense object at 0x000001DD88CDC648>, <tensorflow.python.keras.layers.core.Dense object at 0x000001DD88CDC9C8>, <tensorflow.python.keras.layers.core.Dense object at 0x000001DD88CDCDC8>]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 任何模型都可以访问子层\n",
    "layers_lis = model.layers\n",
    "model.get_layer(index=0, name='dense_1')  # 该函数底层代码本质也是取layers属性，只不过可以通过index和name来查找\n",
    "print(layers_lis)\n",
    "\n",
    "# 除了可以通过add添加层，还可以通过pop删，但是从尾部开始\n",
    "model.pop()\n",
    "print(len(model.layers))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[<tf.Variable 'dense_5/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[ 0.5883374 ,  0.49605572, -0.7962869 ],\n",
      "       [ 0.81412864, -0.5029481 ,  0.12368977],\n",
      "       [-0.14361775, -0.6918834 ,  0.7993928 ],\n",
      "       [-0.8522146 ,  0.1745404 , -0.21200162]], dtype=float32)>, <tf.Variable 'dense_5/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Weights for model ceshi_model have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-ac2b6d068fee>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m                                 name='ceshi_model')\n\u001B[0;32m     15\u001B[0m \u001B[1;31m# print(model.summary())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mweights\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2318\u001B[0m       \u001B[0mA\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mvariables\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2319\u001B[0m     \"\"\"\n\u001B[1;32m-> 2320\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dedup_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_undeduplicated_weights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2321\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2322\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_undeduplicated_weights\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2323\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_undeduplicated_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2324\u001B[0m     \u001B[1;34m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2325\u001B[1;33m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_assert_weights_created\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2326\u001B[0m     \u001B[0mweights\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2327\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_layers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36m_assert_weights_created\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    513\u001B[0m     \u001B[1;31m# When the graph has not been initialized, use the Model's implementation to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    514\u001B[0m     \u001B[1;31m# to check if the weights has been created.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 515\u001B[1;33m     \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFunctional\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_assert_weights_created\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=bad-super-call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    516\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    517\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_assert_weights_created\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2449\u001B[0m                        \u001B[1;34m'Weights are created when the Model is first called on '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2450\u001B[0m                        \u001B[1;34m'inputs or `build()` is called with an `input_shape`.'\u001B[0m \u001B[1;33m%\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2451\u001B[1;33m                        self.name)\n\u001B[0m\u001B[0;32m   2452\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2453\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_check_call_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Weights for model ceshi_model have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "# 初始化后层的权重都是空的，只有在输入时，会初始化\n",
    "\n",
    "layer_1 = keras.layers.Dense(units=3)\n",
    "print(layer_1.weights)\n",
    "\n",
    "x = keras.backend.ones((1, 4))\n",
    "y = layer_1(x)\n",
    "print(layer_1.weights)\n",
    "\n",
    "# 对于没有指定输入形状的模型，是无weights和summary的\n",
    "\n",
    "model = keras.models.Sequential(layers=[keras.layers.Dense(6),\n",
    "                                        keras.layers.Dense(10)],\n",
    "                                name='ceshi_model')\n",
    "print(model.summary())  # 都会报错，因为无具体形状，模型无法构建\n",
    "print(model.weights)\n",
    "# 故应最初add一个Input对象来启动模型，或者用第一层的input_shape来代替\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_9:0\", shape=(None, 250, 250, 3), dtype=float32)\n",
      "[<tf.Tensor 'input_9:0' shape=(None, 250, 250, 3) dtype=float32>]\n",
      "Tensor(\"conv2d_24/Relu:0\", shape=(None, 123, 123, 32), dtype=float32)\n",
      "Tensor(\"conv2d_25/Relu:0\", shape=(None, 121, 121, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 一旦构建成功，每层都会有input和output属性，可以调用\n",
    "# 这样可以方便我们进行特征提取\n",
    "\n",
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "print(initial_model.input)  # 把模型当层来对待，来调用输入属性\n",
    "print(initial_model.inputs)  # 模型输入的列表\n",
    "print(initial_model.layers[1].input)  # 对单个层，只有input而无inputs属性\n",
    "print(initial_model.layers[1].output)\n",
    "\n",
    "# 除此之外，每层都有一个可以冻结它的控制属性\n",
    "# 最爱常用于迁移学习时，需要冻结base，训练顶层\n",
    "initial_model.layers[1].trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}