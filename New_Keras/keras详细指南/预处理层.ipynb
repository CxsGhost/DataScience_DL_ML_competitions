{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用预处理层，可更方便的创建端到端的模型\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 可用的预处理层\n",
    "\n",
    "# 核心的预处理层\n",
    "keras.layers.experimental.preprocessing.TextVectorization\n",
    "keras.layers.experimental.preprocessing.Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 结构化数据预处理层\n",
    "\n",
    "# 将整数特征转化为one-hot，multi—hot，tf-idf来表示\n",
    "keras.layers.experimental.preprocessing.CategoryEncoding\n",
    "\n",
    "# 执行分类特征hash，也称为“hash trick”\n",
    "keras.layers.experimental.preprocessing.Hashing\n",
    "\n",
    "# 将连续的数字特征转化为整数分类特征\n",
    "keras.layers.experimental.preprocessing.Discretization\n",
    "\n",
    "# 将将字符值值转化为整数索引\n",
    "keras.layers.experimental.preprocessing.StringLookup\n",
    "\n",
    "# 将整数分类值转化为整数索引\n",
    "keras.layers.experimental.preprocessing.IntegerLookup\n",
    "\n",
    "# 特征交叉，将分类特征合并为为共想现特征，例如有特征值a，b，则可以提供组合特征“ab同时存在”\n",
    "keras.layers.experimental.preprocessing.CategoryCrossing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 图像预处理层\n",
    "\n",
    "# 将一批图像调整为目标尺寸\n",
    "keras.layers.experimental.preprocessing.Resizing\n",
    "\n",
    "# 重新缩放和偏移一批图像的均值，例如[0, 255]->[0, 1]\n",
    "keras.layers.experimental.preprocessing.Rescaling\n",
    "\n",
    "# 将一批图像进行中心剪裁\n",
    "keras.layers.experimental.preprocessing.CenterCrop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 将图像数据进行数据增强\n",
    "keras.layers.experimental.preprocessing.RandomCrop\n",
    "keras.layers.experimental.preprocessing.RandomFlip\n",
    "keras.layers.experimental.preprocessing.RandomTranslation\n",
    "keras.layers.experimental.preprocessing.RandomRotation\n",
    "keras.layers.experimental.preprocessing.RandomZoom\n",
    "keras.layers.experimental.preprocessing.RandomHeight\n",
    "keras.layers.experimental.preprocessing.RandomWidth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# adapt()方法\n",
    "# 某些预处理层具有内部状态，必须根据训练数据的样本进行计算\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "preprocessing.TextVectorization\n",
    "preprocessing.Normalization  # 保存特征的均值和方差\n",
    "preprocessing.StringLookup, preprocessing.IntegerLookup  # 保存输入和输出索引之间的映射\n",
    "preprocessing.CategoryEncoding  # 保存输入值的索引\n",
    "preprocessing.Discretization  # 保存值区间边界\n",
    "\n",
    "# 关键在于 这些层是不可训练的，在训练前必须adapt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 例如Normalization\n",
    "data = np.random.randint(low=-10, high=10, size=(2, 3))\n",
    "prep = keras.layers.experimental.preprocessing.Normalization()\n",
    "prep.adapt(data)\n",
    "nor_data = prep(data)\n",
    "print(keras.backend.std(nor_data))\n",
    "print(keras.backend.mean(nor_data))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'ῥ᾽', 'ἔλθωσι', 'οἵ ῥ᾽', 'οἵ', 'μὲν', 'διὰ', 'αἱ', 'ῥ᾽ ἔτυμα κραίνουσι', 'ῥ᾽ ἔτυμα', 'ῥ᾽ ἐλεφαίρονται ἔπε᾽', 'ῥ᾽ ἐλεφαίρονται', 'ὅτε κέν τις', 'ὅτε κέν', 'ὅτε', 'ὄνειροι ἀμήχανοι ἀκριτόμυθοι', 'ὄνειροι ἀμήχανοι', 'ὄνειροι', 'ὀνείρων', 'ἴδηται', 'ἦ τοι μὲν', 'ἦ τοι', 'ἦ', 'ἔτυμα κραίνουσι βροτῶν', 'ἔτυμα κραίνουσι', 'ἔτυμα', 'ἔπε᾽ ἀκράαντα φέροντες', 'ἔπε᾽ ἀκράαντα', 'ἔπε᾽', 'ἔλθωσι θύραζε', 'ἔλθωσι διὰ πριστοῦ', 'ἔλθωσι διὰ', 'ἐλεφαίρονται ἔπε᾽ ἀκράαντα', 'ἐλεφαίρονται ἔπε᾽', 'ἐλεφαίρονται', 'ἐλέφαντος', 'ἐλέφαντι', 'ἀνθρώποισι', 'ἀμενηνῶν εἰσὶν ὀνείρων', 'ἀμενηνῶν εἰσὶν', 'ἀμενηνῶν', 'ἀμήχανοι ἀκριτόμυθοι', 'ἀμήχανοι', 'ἀκριτόμυθοι', 'ἀκράαντα φέροντες', 'ἀκράαντα', 'φέροντες', 'τῶν οἳ μέν', 'τῶν οἳ', 'τῶν', 'τοι μὲν ὄνειροι', 'τοι μὲν', 'τοι', 'τις ἴδηται', 'τις', 'τι πάντα τελείεται', 'τι πάντα', 'τι', 'τετεύχαται αἱ δ᾽', 'τετεύχαται αἱ', 'τετεύχαται', 'τελείεται ἀνθρώποισι', 'τελείεται', 'τε πύλαι ἀμενηνῶν', 'τε πύλαι', 'τε', 'πύλαι ἀμενηνῶν εἰσὶν', 'πύλαι ἀμενηνῶν', 'πύλαι', 'πριστοῦ ἐλέφαντος', 'πριστοῦ', 'πάντα τελείεται ἀνθρώποισι', 'πάντα τελείεται', 'πάντα', 'οὐδέ τι πάντα', 'οὐδέ τι', 'οὐδέ', 'οἵ ῥ᾽ ἔτυμα', 'οἵ ῥ᾽ ἐλεφαίρονται', 'οἳ μέν κ᾽', 'οἳ μέν', 'οἳ', 'οἱ δὲ διὰ', 'οἱ δὲ', 'οἱ', 'ξεῖν᾽ ἦ τοι', 'ξεῖν᾽ ἦ', 'ξεῖν᾽', 'ξεστῶν κεράων ἔλθωσι', 'ξεστῶν κεράων', 'ξεστῶν', 'μὲν ὄνειροι ἀμήχανοι', 'μὲν ὄνειροι', 'μὲν γὰρ κεράεσσι', 'μὲν γὰρ', 'μέν κ᾽ ἔλθωσι', 'μέν κ᾽', 'μέν', 'κ᾽ ἔλθωσι διὰ']\n",
      "100\n",
      "tf.Tensor(\n",
      "[[88 23 53  6 18 43 44 87 22 52 93 17 42 86 21 51 92 16  0  0  0  0  0  0]\n",
      " [ 1 77 58 74 63 38  1 76 57 73 62  1 75 56 72  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1 66 69 41  1 19  1  1 65 68 40  1  1  1 64 67 39  0  0  0  0  0  0]\n",
      " [ 8  6  1  1 61  8  1 37  1 95  1  1 60  1  1  1 94  1  1 59  1  0  0  0]\n",
      " [50 82 98  1  3  7 71 36 49 81 97  1 32  1 70 48 80 96 99 31  1  0  0  0]\n",
      " [ 5  2 35 29 46 47  4 12 34 28 45 79 11 33 27  0  0  0  0  0  0  0  0  0]\n",
      " [85  1  7 91  1  3  1 84  1  1 90  1 30 83  1  1 89  1  0  0  0  0  0  0]\n",
      " [ 5  2 26  1  1 15  1 55 20  4 10 25  1  1 14  1 54 78  9 24  1  1 13  1]], shape=(8, 24), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 再例如，对StringLookUp和TextVectorization，可以传入一个字符串列表\n",
    "data = [\n",
    "    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι\",\n",
    "    \"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι.\",\n",
    "    \"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:\",\n",
    "    \"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:\",\n",
    "    \"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,\",\n",
    "    \"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:\",\n",
    "    \"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,\",\n",
    "    \"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται.\",\n",
    "]\n",
    "layer = keras.layers.experimental.preprocessing.TextVectorization(max_tokens=100, ngrams=(1, 2, 3))\n",
    "layer.adapt(data)\n",
    "print(layer.get_vocabulary())\n",
    "print(len(layer.get_vocabulary()))\n",
    "vec_data = layer(data)\n",
    "print(vec_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 4 5 1]\n",
      " [5 1 3 1]], shape=(2, 4), dtype=int64)\n",
      "['', '[UNK]', 'a', 'b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "# 如果手上已有图层状态设置，则可以不通过adapt而直接设置，最简单的比如vocabulary\n",
    "vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
    "data = tf.constant([[\"a\", \"c\", \"d\", \"p\"], [\"d\", \"z\", \"b\", \"o\"]])\n",
    "layer = keras.layers.experimental.preprocessing.StringLookup(vocabulary=vocab)\n",
    "vec_data = layer(data)\n",
    "print(vec_data)\n",
    "print(layer.get_vocabulary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 一些用于快速熟悉的例子\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "rescaling_5 (Rescaling)      (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 图像数据增强\n",
    "DataAugmentation = keras.models.Sequential(layers=[keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal',\n",
    "                                                                                                      name='flip_layer'),\n",
    "                                                   keras.layers.experimental.preprocessing.RandomRotation(factor=0.1,\n",
    "                                                                                                          name='rotation_layer'),\n",
    "                                                   keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.1,\n",
    "                                                                                                      width_factor=0.15,\n",
    "                                                                                                      name='zoom_layer')])\n",
    "model_input = keras.Input(shape=(32, 32, 3),\n",
    "                          dtype='int32',\n",
    "                          name='input')\n",
    "print(model_input.shape[1: ])\n",
    "x = DataAugmentation(model_input)\n",
    "x = keras.layers.experimental.preprocessing.Rescaling(scale=1 / 255.0, offset=0.0)(x)\n",
    "base_model = keras.applications.ResNet50(weights=None,\n",
    "                                         input_shape=model_input.shape[1: ],\n",
    "                                         include_top=False)\n",
    "model_output = base_model(x)\n",
    "model = keras.models.Model(inputs=[model_input], outputs=[model_output])\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[6 5 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[6 5 0]\n",
      "  [4 3 2]]], shape=(2, 2, 3), dtype=int64)\n",
      "['', '[UNK]', '5', '4', '3', '2', '1']\n",
      "False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-28-f80244960f7d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mencoder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCategoryEncoding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_mode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'binary'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mencoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madapt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 由于字符索引数值在某些时候是无意义的，故将其转化为one-hot编码\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\category_encoding.py\u001B[0m in \u001B[0;36madapt\u001B[1;34m(self, data, reset_state)\u001B[0m\n\u001B[0;32m    201\u001B[0m       raise RuntimeError(\"CategoryEncoding can't be adapted after being called \"\n\u001B[0;32m    202\u001B[0m                          \"if max_tokens is None.\")\n\u001B[1;32m--> 203\u001B[1;33m     \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mCategoryEncoding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madapt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreset_state\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    204\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    205\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_set_state_variables\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mupdates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_preprocessing_layer.py\u001B[0m in \u001B[0;36madapt\u001B[1;34m(self, data, reset_state)\u001B[0m\n\u001B[0;32m    205\u001B[0m       \u001B[1;31m# until we've gotten an exception indicating that we have no more data.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m       \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 207\u001B[1;33m         \u001B[0maccumulator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_combiner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_element\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccumulator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    208\u001B[0m         \u001B[0mdata_element\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[1;31m# Note that this belongs to the outer indentation of 'try' - we need to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\category_encoding.py\u001B[0m in \u001B[0;36mcompute\u001B[1;34m(self, values, accumulator)\u001B[0m\n\u001B[0;32m    368\u001B[0m       \u001B[1;32mfor\u001B[0m \u001B[0mvalue\u001B[0m \u001B[1;32min\u001B[0m \u001B[0melement\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m         \u001B[0mcurrent_max_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maccumulator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMAX_VALUE_IDX\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 370\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[0mvalue\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mcurrent_max_value\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    371\u001B[0m           \u001B[0maccumulator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMAX_VALUE_IDX\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_compute_idf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# 对字符串特征进行one-hot编码\n",
    "all_data = tf.constant(['1', '2', '3', '4', '5'])\n",
    "data = tf.constant([[['1', '2', ''], ['', '', '']],\n",
    "                     [['1', '2', ''], ['3', '4', '5']]])\n",
    "indexer = keras.layers.experimental.preprocessing.StringLookup(mask_token='')\n",
    "indexer.adapt(all_data)  # 按照词频统计方法将每个字符给予索引，形成词库字典(类似token）\n",
    "print(indexer(data))\n",
    "print(indexer.get_vocabulary())\n",
    "\n",
    "encoder = keras.layers.experimental.preprocessing.CategoryEncoding(output_mode='binary')\n",
    "encoder.adapt(indexer(data))  # 由于字符索引数值在某些时候是无意义的，故将其转化为one-hot编码\n",
    "print(encoder(data))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -2, 20, 10, 0, 50, 30]\n",
      "7\n",
      "tf.Tensor(\n",
      "[[3 2 2 5 6 4]\n",
      " [3 2 3 4 2 0]\n",
      " [1 0 0 0 0 0]], shape=(3, 6), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ True  True  True  True  True False]\n",
      " [ True  True  True False False False]], shape=(2, 6), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ True  True  True  True  True False]\n",
      " [ True  True  True False False False]], shape=(2, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# 对整数特征进行one-hot编码\n",
    "data = tf.constant([[10, 20, 20, 50, 30, 0],\n",
    "                    [10, 20, 10, 0, 20, -1],\n",
    "                    [10, -1, -1, -1, -1, -1]], dtype='int32')\n",
    "indexer = keras.layers.experimental.preprocessing.IntegerLookup(mask_value=-1,\n",
    "                                                                oov_value=-2)\n",
    "indexer.adapt(data)\n",
    "print(indexer.get_vocabulary())\n",
    "print(len(indexer.get_vocabulary()))\n",
    "data = tf.constant([[10, 20, 20, 50, 30, 0],\n",
    "                    [10, 20, 10, 0, 20, -1],\n",
    "                    [100, -1, -1, -1, -1, -1]], dtype='int32')\n",
    "print(indexer(data))\n",
    "\n",
    "data = tf.constant([[[1], [2], [2], [5], [3], [0]],\n",
    "                    [[1], [2], [4], [0], [0], [0]]], dtype='int32')\n",
    "data = tf.constant([[1, 2, 2, 5, 3, 0],\n",
    "                    [1, 2, 4, 0, 0, 0]], dtype='int32')\n",
    "data_2 = tf.constant([[1, 2, 2, 5, 3, 0],\n",
    "                    [1, 1, 5, 0, 0, 0]], dtype='int32')\n",
    "\n",
    "emb = keras.layers.Embedding(input_dim=len(indexer.get_vocabulary()), output_dim=4, mask_zero=True)\n",
    "emb_2 = keras.layers.Embedding(input_dim=len(indexer.get_vocabulary()), output_dim=2, mask_zero=True)\n",
    "\n",
    "# data_2 = emb_2(data_2)\n",
    "# data = emb(data)\n",
    "# concat = keras.layers.Concatenate()\n",
    "# new_data = concat([data, data_2])\n",
    "# print(new_data._keras_mask)\n",
    "#\n",
    "# data_3 = tf.constant(np.random.normal(size=(data.shape[:-1] + (2, ))))\n",
    "# new_data_3 = concat([data, data_3])\n",
    "# print(new_data_3._keras_mask)\n",
    "\n",
    "print(emb(data)._keras_mask)\n",
    "emb_input = keras.Input(shape=(None, ), dtype='float32')\n",
    "emb_output = emb(emb_input)\n",
    "emb_model = keras.models.Model(inputs=[emb_input], outputs=[emb_output])\n",
    "print(emb_model(data)._keras_mask)\n",
    "\n",
    "# add = keras.layers.Add()\n",
    "# temp = keras.backend.ones_like(data)\n",
    "# result = add([data, temp])\n",
    "# print(result)\n",
    "# print(result._keras_mask)\n",
    "# encoder = keras.layers.experimental.preprocessing.CategoryEncoding(output_mode='binary')\n",
    "# encoder.adapt(indexer(data))\n",
    "# print(encoder(indexer(data)))\n",
    "#\n",
    "# test_data = np.array([10, 10, 20, 50, 60, 0])\n",
    "# print(indexer(test_data))\n",
    "# print(encoder(indexer(test_data)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 0. 0. 0.]], shape=(2, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ True  True  True  True]\n",
      " [ True False False False]], shape=(2, 4), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[0.25 0.25 0.25 0.25]\n",
      " [1.   0.   0.   0.  ]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "soft_data = tf.constant([[[1], [1], [1], [1]],\n",
    "                         [[1], [0], [0], [0]]], dtype='float32')\n",
    "print(keras.layers.Reshape(target_shape=(4, ))(soft_data))\n",
    "soft_data_1 = tf.constant([[1, 1, 1, 1],\n",
    "                         [1, 0, 0, 0]], dtype='float32')\n",
    "soft_data = keras.layers.Masking(mask_value=0)(soft_data)\n",
    "print(soft_data._keras_mask)\n",
    "soft_data = tf.where(soft_data._keras_mask, soft_data_1, tf.ones_like(soft_data_1) * (-2e32))\n",
    "print(tf.nn.softmax(soft_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]], shape=(2, 3, 10), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'supports_masking'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-40-d13d44a5a03a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'float32'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msupports_masking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'supports_masking'"
     ]
    }
   ],
   "source": [
    "data = tf.ones(shape=(2, 1, 10))\n",
    "print(keras.backend.tile(data, (1, 3, 1)))\n",
    "print(keras.layers.Input(shape=(None, ), dtype='float32').supports_masking)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-67bee2e94ec1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m temp = tf.constant([[1, 1, 1],\n\u001B[0m\u001B[0;32m      2\u001B[0m                     [2, 2, 2]])\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtemp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "temp = tf.constant([[1, 1, 1],\n",
    "                    [2, 2, 0]])\n",
    "print(tf.sequence_mask(keras.layers.Masking(mask_value=0)(temp)))\n",
    "# temp_1 = tf.constant([[1, 1, 1]])\n",
    "# print(temp - temp_1)\n",
    "# print(tf.expand_dims(temp, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[51]\n",
      " [61]\n",
      " [26]\n",
      " ...\n",
      " [62]\n",
      " [45]\n",
      " [ 2]], shape=(10000, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]], shape=(10000, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 使用hash技巧应用于整数类特征\n",
    "# 如果特征值中出现了许多不同的值，而每个值仅仅在数据中出现几次，则索引编制法不太好\n",
    "# 所以将值hash到固定大小的向量，这样使得特征空间大小易于管理，且无需显示索引\n",
    "# 简单来说，在实际应用中可能会遇到特征太多的情况，不好降维，与使用这样的方法强行降维，虽然出来的结果不好解释，并且会出现很多特征碰撞的可能性，但事实证明这并不影响解决问题\n",
    "data = np.random.randint(low=0, high=100000, size=(10000, 1))\n",
    "hasher = keras.layers.experimental.preprocessing.Hashing(num_bins=64, salt=1337)\n",
    "\n",
    "encoder = keras.layers.experimental.preprocessing.CategoryEncoding(max_tokens=64, output_mode='binary')\n",
    "print(hasher(data))\n",
    "print(encoder(hasher(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]], shape=(3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 将文本数据编码为数字索引向量，该方法主要适用于将数据扔进embedding层之前\n",
    "data =  tf.constant(['10 20 50', '20 30', '',\n",
    "                     '10', '', ''])\n",
    "\n",
    "encoder = keras.layers.experimental.preprocessing.TextVectorization(output_mode='binary')\n",
    "encoder.adapt(data)\n",
    "\n",
    "data =  tf.constant(['10', 'no', ''])\n",
    "cope_data = encoder(data)\n",
    "print(cope_data)\n",
    "# embeddinger = keras.layers.Embedding(input_dim=len(text_vectorizer.get_vocabulary()), output_dim=10)\n",
    "#\n",
    "# print(embeddinger(cope_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', 'the', 'side', 'you', 'with', 'will', 'wider', 'them', 'than', 'sky', 'put', 'other', 'one', 'is', 'for', 'ease', 'contain', 'by', 'brain', 'beside', 'and']\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(5, 21), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 使用multi——hot将文本编码为密集的ngram矩阵\n",
    "# 多热编码就是某个特征可以含有多个值，即某条向量中可以有多个1，是独热的进化\n",
    "data = tf.constant(\n",
    "    [\n",
    "        \"The Brain is wider than the Sky\",\n",
    "        \"For put them side by side\",\n",
    "        \"The one the other will contain\",\n",
    "        \"With ease and You beside\",\n",
    "        ''\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_vectorizer = keras.layers.experimental.preprocessing.TextVectorization(output_mode='binary')\n",
    "text_vectorizer.adapt(data)\n",
    "print(text_vectorizer.get_vocabulary())\n",
    "print(text_vectorizer(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', 'the', 'side', 'you beside', 'you', 'with ease', 'with', 'will contain', 'will', 'wider than', 'wider', 'them side', 'them', 'the sky', 'the other', 'the one', 'the brain', 'than the', 'than', 'sky', 'side by', 'put them', 'put', 'other will', 'other', 'one the', 'one', 'is wider', 'is', 'for put', 'for', 'ease and', 'ease', 'contain', 'by side', 'by', 'brain is', 'brain', 'beside', 'and you', 'and']\n",
      "tf.Tensor(\n",
      "[[0.        1.6945957 0.        0.        0.        0.        0.\n",
      "  0.        0.        1.0986123 1.0986123 0.        0.        1.0986123\n",
      "  0.        0.        1.0986123 1.0986123 1.0986123 1.0986123 0.\n",
      "  0.        0.        0.        0.        0.        0.        1.0986123\n",
      "  1.0986123 0.        0.        0.        0.        0.        0.\n",
      "  0.        1.0986123 1.0986123 0.        0.        0.       ]\n",
      " [0.        0.        2.1972246 0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        1.0986123 1.0986123 0.\n",
      "  0.        0.        0.        0.        0.        0.        1.0986123\n",
      "  1.0986123 1.0986123 0.        0.        0.        0.        0.\n",
      "  0.        1.0986123 1.0986123 0.        0.        0.        1.0986123\n",
      "  1.0986123 0.        0.        0.        0.        0.       ]\n",
      " [0.        1.6945957 0.        0.        0.        0.        0.\n",
      "  1.0986123 1.0986123 0.        0.        0.        0.        0.\n",
      "  1.0986123 1.0986123 0.        0.        0.        0.        0.\n",
      "  0.        0.        1.0986123 1.0986123 1.0986123 1.0986123 0.\n",
      "  0.        0.        0.        0.        0.        1.0986123 0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        1.0986123 1.0986123 1.0986123 1.0986123\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        1.0986123 1.0986123 0.        0.\n",
      "  0.        0.        0.        1.0986123 1.0986123 1.0986123]], shape=(4, 41), dtype=float32)\n",
      "(4, 41)\n"
     ]
    }
   ],
   "source": [
    "# 使用tf-idf加权将文本编码到ngram矩阵\n",
    "# 本质是先使用ngram，然后将每条使用multi-hot表示，然后再计算tf-idf值，将其中的1替换成对应的tf-idf值\n",
    "data = tf.constant(\n",
    "    [\n",
    "        \"The Brain is wider than the Sky\",\n",
    "        \"For put them side by side\",\n",
    "        \"The one the other will contain\",\n",
    "        \"With ease and You beside\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_vectorizer = keras.layers.experimental.preprocessing.TextVectorization(output_mode='tf-idf', ngrams=(1, 2))\n",
    "text_vectorizer.adapt(data)\n",
    "print(text_vectorizer.get_vocabulary())\n",
    "print(text_vectorizer(data))\n",
    "print(text_vectorizer(data).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}