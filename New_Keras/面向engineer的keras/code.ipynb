{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=g, enable=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# keras接收三种输入 numpy.array,tfdataset,python generator\n",
    "\n",
    "# Dataset:\n",
    "from tensorflow import keras\n",
    "\n",
    "keras.preprocessing.image_dataset_from_directory\n",
    "keras.preprocessing.text_dataset_from_directory\n",
    "...\n",
    "\n",
    "# 已分类存放的图像或文本，将会按照文件夹字母排序来作为label\n",
    "# 也可以显示的指定类\n",
    "dataset = keras.preprocessing.image_dataset_from_directory('path',\n",
    "                                                           batch_size=64,\n",
    "                                                           image_size=(200, 200),\n",
    "                                                           class_names=['class_a', 'class_b'])\n",
    "dataset = keras.preprocessing.text_dataset_from_directory('path',\n",
    "                                                          batch_size=64,\n",
    "                                                          class_names=['class_a', 'class_b'])\n",
    "# 可迭代对象有shape和type\n",
    "for data, label in dataset:\n",
    "    print(data.shape, data.dtype)\n",
    "    print(label.shape, label.dtype)\n",
    "\n",
    "# 除此之外,还可以从csv文件夹加载结构化数据\n",
    "import tensorflow as tf\n",
    "tf.data.experimental.make_csv_dataset\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 5 2 9 3]\n",
      " [7 6 2 8 3]], shape=(2, 5), dtype=int64)\n",
      "['[UNK]', 'the', 'sample', 'this is', 'this', 'the 2nd', 'the 1st', 'is the', 'is', 'heres the', 'heres', 'and heres', 'and', '2nd sample', '2nd', '1st sample', '1st']\n",
      "17\n",
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]], shape=(2, 17), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 理想模型是端到端的，即数据预处理也应包含在模型中\n",
    "\n",
    "# 文本数据预处理\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "train_data = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])\n",
    "\n",
    "# 类似于sklearn的fit，transform\n",
    "vectorizer = TextVectorization(output_mode='int')  # 整数编码\n",
    "vectorizer.adapt(train_data)\n",
    "integer_data = vectorizer(train_data)\n",
    "print(integer_data)\n",
    "\n",
    "# 使用n-gram模型分词，并转换为one-hot，ngrmas参数是扫描窗口的MAX大小N，即将会从1-N进行所有可能的分法\n",
    "vectorizer = TextVectorization(output_mode='binary', ngrams=2)\n",
    "vectorizer.adapt(train_data)\n",
    "print(vectorizer.get_vocabulary())\n",
    "print(len(vectorizer.get_vocabulary()))\n",
    "integer_data = vectorizer(train_data)\n",
    "print(integer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ -9.  -9.  -4.]\n",
      "   [  6.  -4.   3.]\n",
      "   [ -2.  -5.   8.]\n",
      "   [  6. -10.  -7.]\n",
      "   [-10.   5.   0.]]\n",
      "\n",
      "  [[  7.  -9.   4.]\n",
      "   [ -1.  -6.   5.]\n",
      "   [ -1.   4.  -8.]\n",
      "   [  9. -10.   6.]\n",
      "   [  7.  -1.   5.]]\n",
      "\n",
      "  [[  0.   5.   7.]\n",
      "   [ -8.  -7.   3.]\n",
      "   [  6.  -9.  -8.]\n",
      "   [  6.   0.  -8.]\n",
      "   [ -5.  -3.   0.]]\n",
      "\n",
      "  [[  2.   1.   5.]\n",
      "   [ -8.   5.  -6.]\n",
      "   [  9.   9.  -6.]\n",
      "   [ -3.   3.  -4.]\n",
      "   [  5.   4.  -6.]]\n",
      "\n",
      "  [[  6.   1.  -7.]\n",
      "   [ -3.  -2.  -7.]\n",
      "   [ -7.   3.   6.]\n",
      "   [ -1. -10.   4.]\n",
      "   [ -3.  -5.  -2.]]]], shape=(1, 5, 5, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-1.5678242  -1.225245   -0.5938274 ]\n",
      "   [ 0.95549804 -0.35007     0.6582184 ]\n",
      "   [-0.39027384 -0.525105    1.5525368 ]\n",
      "   [ 0.95549804 -1.40028    -1.1304185 ]\n",
      "   [-1.7360457   1.225245    0.12162731]]\n",
      "\n",
      "  [[ 1.1237195  -1.225245    0.837082  ]\n",
      "   [-0.22205235 -0.70014     1.0159457 ]\n",
      "   [-0.22205235  1.05021    -1.3092822 ]\n",
      "   [ 1.4601625  -1.40028     1.1948093 ]\n",
      "   [ 1.1237195   0.175035    1.0159457 ]]\n",
      "\n",
      "  [[-0.05383087  1.225245    1.3736731 ]\n",
      "   [-1.3996028  -0.87517506  0.6582184 ]\n",
      "   [ 0.95549804 -1.225245   -1.3092822 ]\n",
      "   [ 0.95549804  0.35007    -1.3092822 ]\n",
      "   [-0.89493835 -0.175035    0.12162731]]\n",
      "\n",
      "  [[ 0.28261212  0.525105    1.0159457 ]\n",
      "   [-1.3996028   1.225245   -0.95155483]\n",
      "   [ 1.4601625   1.9253851  -0.95155483]\n",
      "   [-0.55849534  0.87517506 -0.5938274 ]\n",
      "   [ 0.7872765   1.05021    -0.95155483]]\n",
      "\n",
      "  [[ 0.95549804  0.525105   -1.1304185 ]\n",
      "   [-0.55849534  0.         -1.1304185 ]\n",
      "   [-1.2313813   0.87517506  1.1948093 ]\n",
      "   [-0.22205235 -1.40028     0.837082  ]\n",
      "   [-0.55849534 -0.525105   -0.23610005]]]], shape=(1, 5, 5, 3), dtype=float32)\n",
      "0.9999999\n",
      "-1.9868216e-09\n",
      "0.99999994\n"
     ]
    }
   ],
   "source": [
    "# 张量数据预处理\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "train_data = np.random.randint(low=-10, high=10, size=(1, 5, 5, 3))\n",
    "train_data = train_data.astype(np.float64)\n",
    "\n",
    "normalization = Normalization(axis=-1)\n",
    "print(normalization(train_data))\n",
    "normalization.adapt(train_data)\n",
    "\n",
    "normal_data = normalization(train_data)\n",
    "print(normal_data)\n",
    "print(np.var(normal_data))\n",
    "print(np.mean(normal_data))\n",
    "print(np.std(normal_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[153.  98. 221.]\n",
      "   [152.  64.  76.]\n",
      "   [ 54. 198. 148.]\n",
      "   ...\n",
      "   [110. 158.  61.]\n",
      "   [ 37.  33.  32.]\n",
      "   [101.  71. 172.]]\n",
      "\n",
      "  [[231. 253.  91.]\n",
      "   [ 80.  50. 181.]\n",
      "   [199. 168. 138.]\n",
      "   ...\n",
      "   [165. 208. 123.]\n",
      "   [ 17.  36. 157.]\n",
      "   [ 65.  58. 177.]]\n",
      "\n",
      "  [[205.  91.  45.]\n",
      "   [161. 241. 200.]\n",
      "   [ 68.  65. 138.]\n",
      "   ...\n",
      "   [ 35. 237.  78.]\n",
      "   [ 52.   5. 225.]\n",
      "   [190.  63.  75.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100. 254. 114.]\n",
      "   [  9. 201. 205.]\n",
      "   [148. 170. 202.]\n",
      "   ...\n",
      "   [ 83.  72. 245.]\n",
      "   [147.  53.  73.]\n",
      "   [206.   4. 250.]]\n",
      "\n",
      "  [[197.  82. 127.]\n",
      "   [ 14. 247. 220.]\n",
      "   [154.   2. 154.]\n",
      "   ...\n",
      "   [ 84. 229. 241.]\n",
      "   [179.   0. 167.]\n",
      "   [219.  35. 116.]]\n",
      "\n",
      "  [[ 36.  35. 132.]\n",
      "   [199.  13.   2.]\n",
      "   [121. 228.  82.]\n",
      "   ...\n",
      "   [161.  12. 225.]\n",
      "   [244. 223. 102.]\n",
      "   [143. 128.  72.]]]\n",
      "\n",
      "\n",
      " [[[ 70. 151.  92.]\n",
      "   [182.  61. 195.]\n",
      "   [ 21.  27.  29.]\n",
      "   ...\n",
      "   [113.  96.  37.]\n",
      "   [159.  32. 157.]\n",
      "   [235. 246.  77.]]\n",
      "\n",
      "  [[159.  14. 122.]\n",
      "   [251. 149.  23.]\n",
      "   [255. 179.  15.]\n",
      "   ...\n",
      "   [222. 221.  60.]\n",
      "   [ 15.  10.  34.]\n",
      "   [  0. 149.  70.]]\n",
      "\n",
      "  [[235.  43.  94.]\n",
      "   [202. 193. 129.]\n",
      "   [103. 120. 166.]\n",
      "   ...\n",
      "   [ 36.  33. 125.]\n",
      "   [131.  30. 141.]\n",
      "   [ 41. 221.  55.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 21. 152. 218.]\n",
      "   [129.   1.  29.]\n",
      "   [ 55. 167. 242.]\n",
      "   ...\n",
      "   [248.  18. 127.]\n",
      "   [224.  47. 154.]\n",
      "   [160. 159.   9.]]\n",
      "\n",
      "  [[ 17. 113.  32.]\n",
      "   [200.   0. 194.]\n",
      "   [251.  21. 250.]\n",
      "   ...\n",
      "   [136. 192.  69.]\n",
      "   [  7.  95. 149.]\n",
      "   [160.  72. 147.]]\n",
      "\n",
      "  [[ 45. 155.  21.]\n",
      "   [169. 158.  22.]\n",
      "   [ 88. 247. 213.]\n",
      "   ...\n",
      "   [ 76. 233. 228.]\n",
      "   [234. 184.  59.]\n",
      "   [137. 148. 111.]]]\n",
      "\n",
      "\n",
      " [[[116.  32. 198.]\n",
      "   [193. 156. 103.]\n",
      "   [237.  28. 113.]\n",
      "   ...\n",
      "   [241. 201.   8.]\n",
      "   [ 78.  93.  78.]\n",
      "   [123.  37.  61.]]\n",
      "\n",
      "  [[ 88. 198.  25.]\n",
      "   [219.   2.  89.]\n",
      "   [119.   5. 104.]\n",
      "   ...\n",
      "   [ 96. 121. 148.]\n",
      "   [198.  62. 220.]\n",
      "   [ 20. 148. 154.]]\n",
      "\n",
      "  [[136.  87.  93.]\n",
      "   [ 48.  17. 145.]\n",
      "   [103. 180. 213.]\n",
      "   ...\n",
      "   [214. 163. 238.]\n",
      "   [ 36. 136.  61.]\n",
      "   [253. 153.  65.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[241.  56.  42.]\n",
      "   [ 75. 230. 134.]\n",
      "   [224. 143. 113.]\n",
      "   ...\n",
      "   [190.  40. 130.]\n",
      "   [139. 129. 156.]\n",
      "   [108. 244.  68.]]\n",
      "\n",
      "  [[112. 214. 111.]\n",
      "   [173. 156.  87.]\n",
      "   [ 57. 226.   2.]\n",
      "   ...\n",
      "   [176. 128. 196.]\n",
      "   [219.   2. 231.]\n",
      "   [177.   2.  41.]]\n",
      "\n",
      "  [[ 98. 247.  38.]\n",
      "   [169. 160. 243.]\n",
      "   [182. 177. 219.]\n",
      "   ...\n",
      "   [ 31.  32. 100.]\n",
      "   [ 65. 217. 100.]\n",
      "   [ 84. 206.  50.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[178.  80. 244.]\n",
      "   [ 84. 106.  83.]\n",
      "   [ 24.  33. 156.]\n",
      "   ...\n",
      "   [ 99. 235.  86.]\n",
      "   [ 86. 170. 246.]\n",
      "   [189.  27.  86.]]\n",
      "\n",
      "  [[ 48. 188.  30.]\n",
      "   [ 94.   2.  31.]\n",
      "   [120.  38. 217.]\n",
      "   ...\n",
      "   [212.  10. 170.]\n",
      "   [179.  63. 157.]\n",
      "   [140. 143.  21.]]\n",
      "\n",
      "  [[133.  80. 227.]\n",
      "   [ 14. 201. 105.]\n",
      "   [121.  54. 189.]\n",
      "   ...\n",
      "   [216. 237.  82.]\n",
      "   [205.  28.   4.]\n",
      "   [120.  34. 248.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 11.  32. 207.]\n",
      "   [246. 161. 151.]\n",
      "   [230.  60. 199.]\n",
      "   ...\n",
      "   [130. 248. 129.]\n",
      "   [116.  84. 166.]\n",
      "   [230. 212.  56.]]\n",
      "\n",
      "  [[127. 210. 191.]\n",
      "   [101. 167. 171.]\n",
      "   [161. 177.  13.]\n",
      "   ...\n",
      "   [176.  44.  95.]\n",
      "   [ 56. 236. 147.]\n",
      "   [212.  69. 225.]]\n",
      "\n",
      "  [[  7. 122. 124.]\n",
      "   [ 25. 138. 245.]\n",
      "   [ 43.  36. 255.]\n",
      "   ...\n",
      "   [ 17. 220.  48.]\n",
      "   [243.  35. 201.]\n",
      "   [ 62. 196. 156.]]]\n",
      "\n",
      "\n",
      " [[[202. 129. 170.]\n",
      "   [247. 100.  50.]\n",
      "   [132. 239. 119.]\n",
      "   ...\n",
      "   [179. 129.   9.]\n",
      "   [124. 162. 140.]\n",
      "   [249. 181.  95.]]\n",
      "\n",
      "  [[ 39.   8. 149.]\n",
      "   [179. 204. 181.]\n",
      "   [169. 223. 146.]\n",
      "   ...\n",
      "   [ 64. 221. 198.]\n",
      "   [242. 126. 186.]\n",
      "   [  3.  16. 140.]]\n",
      "\n",
      "  [[ 15.  98.  37.]\n",
      "   [  9. 189. 191.]\n",
      "   [ 38. 198.  42.]\n",
      "   ...\n",
      "   [ 92.  93. 201.]\n",
      "   [  5.  75. 255.]\n",
      "   [185.  34. 193.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 78. 201. 148.]\n",
      "   [ 13. 216. 161.]\n",
      "   [106.  62. 238.]\n",
      "   ...\n",
      "   [176. 127. 164.]\n",
      "   [ 49.  25.  47.]\n",
      "   [233.  66. 145.]]\n",
      "\n",
      "  [[170.  39. 170.]\n",
      "   [ 92. 178. 102.]\n",
      "   [ 37. 225. 215.]\n",
      "   ...\n",
      "   [ 53. 109. 108.]\n",
      "   [ 76.  33. 143.]\n",
      "   [230. 107. 135.]]\n",
      "\n",
      "  [[ 86.  42. 208.]\n",
      "   [241.   0.  60.]\n",
      "   [114. 130. 139.]\n",
      "   ...\n",
      "   [142. 155. 127.]\n",
      "   [143.  87.   7.]\n",
      "   [192.  70. 168.]]]\n",
      "\n",
      "\n",
      " [[[ 93. 219.  82.]\n",
      "   [143.  84. 103.]\n",
      "   [ 64. 236.  54.]\n",
      "   ...\n",
      "   [101.  38. 171.]\n",
      "   [113. 245. 229.]\n",
      "   [231.  17. 191.]]\n",
      "\n",
      "  [[ 83.  52. 121.]\n",
      "   [151.  36. 205.]\n",
      "   [ 78. 206.  29.]\n",
      "   ...\n",
      "   [ 81.  88.  43.]\n",
      "   [152.  46.  98.]\n",
      "   [130.  46. 235.]]\n",
      "\n",
      "  [[208.  90. 196.]\n",
      "   [ 65.  86.  19.]\n",
      "   [233. 108.  63.]\n",
      "   ...\n",
      "   [193. 229. 126.]\n",
      "   [ 97. 198. 111.]\n",
      "   [134. 122. 221.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[132. 255. 164.]\n",
      "   [165. 110.  36.]\n",
      "   [164. 156. 180.]\n",
      "   ...\n",
      "   [233. 101. 182.]\n",
      "   [ 72.   9. 113.]\n",
      "   [134.  94.  57.]]\n",
      "\n",
      "  [[146. 235. 200.]\n",
      "   [ 71.  51.   8.]\n",
      "   [ 87.   0.  27.]\n",
      "   ...\n",
      "   [ 66. 243.  51.]\n",
      "   [157. 222.  88.]\n",
      "   [  9.   1. 169.]]\n",
      "\n",
      "  [[103.  22. 200.]\n",
      "   [ 87. 162.  11.]\n",
      "   [ 84. 110.  96.]\n",
      "   ...\n",
      "   [222.  14.  53.]\n",
      "   [252.  88. 167.]\n",
      "   [189.  21. 200.]]]]\n",
      "WARNING:tensorflow:Layer center_crop_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[[[0.43921572 0.09803922 0.85098046]\n",
      "   [0.39607847 0.6039216  0.5568628 ]\n",
      "   [0.81568635 0.01568628 0.7725491 ]\n",
      "   ...\n",
      "   [0.02745098 0.53333336 0.9058824 ]\n",
      "   [0.6627451  0.44705886 0.9607844 ]\n",
      "   [0.4666667  0.12941177 0.45098042]]\n",
      "\n",
      "  [[0.37647063 0.23137257 0.30588236]\n",
      "   [0.10980393 0.07450981 0.47450984]\n",
      "   [0.10980393 0.8000001  0.34509805]\n",
      "   ...\n",
      "   [0.78823537 0.24705884 0.20784315]\n",
      "   [0.8980393  0.5803922  0.36078432]\n",
      "   [0.85098046 0.9607844  0.6784314 ]]\n",
      "\n",
      "  [[0.56078434 0.85098046 0.15294118]\n",
      "   [0.61960787 0.34901962 0.54509807]\n",
      "   [0.32941177 0.31764707 0.37647063]\n",
      "   ...\n",
      "   [0.67058825 0.5921569  0.36078432]\n",
      "   [0.         0.5647059  0.48235297]\n",
      "   [0.5411765  0.882353   0.02745098]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8078432  0.909804   0.52156866]\n",
      "   [0.20000002 0.9725491  0.8745099 ]\n",
      "   [0.627451   0.1764706  0.63529414]\n",
      "   ...\n",
      "   [0.18039216 0.93725497 0.7843138 ]\n",
      "   [0.16078432 0.3921569  0.03921569]\n",
      "   [0.7568628  0.08235294 0.41176474]]\n",
      "\n",
      "  [[0.47450984 0.8705883  0.9176471 ]\n",
      "   [0.04313726 0.62352943 0.16862746]\n",
      "   [0.82745105 0.7254902  0.5764706 ]\n",
      "   ...\n",
      "   [0.5019608  0.32156864 0.23529413]\n",
      "   [0.32941177 0.65882355 0.25490198]\n",
      "   [0.20784315 0.42352945 0.23529413]]\n",
      "\n",
      "  [[0.62352943 0.42352945 0.882353  ]\n",
      "   [0.68235296 0.49803925 0.94117653]\n",
      "   [0.3137255  0.8196079  0.42352945]\n",
      "   ...\n",
      "   [0.18823531 0.49803925 0.8941177 ]\n",
      "   [0.3372549  0.74509805 0.77647066]\n",
      "   [0.74509805 0.34509805 0.03529412]]]\n",
      "\n",
      "\n",
      " [[[0.41176474 0.29803923 0.5176471 ]\n",
      "   [0.8941177  0.5294118  0.61960787]\n",
      "   [0.5019608  0.7294118  0.6313726 ]\n",
      "   ...\n",
      "   [0.5372549  0.04705883 0.14901961]\n",
      "   [0.43921572 0.23529413 0.4156863 ]\n",
      "   [0.80392164 0.63529414 0.41960788]]\n",
      "\n",
      "  [[0.09803922 0.07450981 0.42352945]\n",
      "   [0.07843138 0.8941177  0.27058825]\n",
      "   [0.5803922  0.57254905 0.23529413]\n",
      "   ...\n",
      "   [0.47450984 0.9176471  0.41176474]\n",
      "   [0.627451   0.50980395 0.8117648 ]\n",
      "   [0.28235295 0.3254902  0.1137255 ]]\n",
      "\n",
      "  [[0.97647065 0.5764706  0.9921569 ]\n",
      "   [0.4039216  0.57254905 0.2901961 ]\n",
      "   [0.7254902  0.07450981 0.24705884]\n",
      "   ...\n",
      "   [0.33333334 0.6745098  0.7372549 ]\n",
      "   [0.7058824  0.3529412  0.31764707]\n",
      "   [0.8313726  0.7607844  0.77647066]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.78823537 0.5372549  0.45098042]\n",
      "   [0.68235296 0.30588236 0.7137255 ]\n",
      "   [0.39607847 0.37254903 0.07450981]\n",
      "   ...\n",
      "   [0.9294118  0.19607845 0.72156864]\n",
      "   [0.04313726 0.9960785  0.6392157 ]\n",
      "   [0.02352941 0.28627452 0.2509804 ]]\n",
      "\n",
      "  [[0.6156863  0.6392157  0.20000002]\n",
      "   [0.9215687  0.9843138  0.89019614]\n",
      "   [0.93725497 0.6627451  0.49411768]\n",
      "   ...\n",
      "   [0.5411765  0.94117653 0.6117647 ]\n",
      "   [0.3803922  0.9960785  0.67058825]\n",
      "   [0.6745098  0.5803922  0.7725491 ]]\n",
      "\n",
      "  [[0.34901962 0.20000002 0.75294125]\n",
      "   [0.5882353  0.86666673 0.16470589]\n",
      "   [0.454902   0.43529415 0.34117648]\n",
      "   ...\n",
      "   [0.9843138  0.59607846 0.37647063]\n",
      "   [0.627451   0.20784315 0.48627454]\n",
      "   [0.26666668 0.65882355 0.5294118 ]]]\n",
      "\n",
      "\n",
      " [[[0.8431373  0.52156866 0.18039216]\n",
      "   [0.45098042 0.5254902  0.8980393 ]\n",
      "   [0.13333334 0.41176474 0.82745105]\n",
      "   ...\n",
      "   [0.10588236 0.909804   0.01960784]\n",
      "   [0.96470594 0.62352943 0.08235294]\n",
      "   [0.39607847 0.6313726  0.5058824 ]]\n",
      "\n",
      "  [[0.09019608 0.5803922  0.62352943]\n",
      "   [0.8470589  0.3803922  0.3372549 ]\n",
      "   [0.9215687  0.7568628  0.41176474]\n",
      "   ...\n",
      "   [0.36078432 0.7725491  0.7411765 ]\n",
      "   [0.64705884 0.05490196 0.64705884]\n",
      "   [0.31764707 0.26666668 0.00392157]]\n",
      "\n",
      "  [[0.10196079 0.97647065 0.75294125]\n",
      "   [0.2901961  0.9490197  0.70980394]\n",
      "   [0.6901961  0.21176472 0.69411767]\n",
      "   ...\n",
      "   [0.7058824  0.23529413 0.5019608 ]\n",
      "   [0.6745098  0.7058824  0.627451  ]\n",
      "   [0.22352943 0.8235295  0.6313726 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117648 0.37647063 0.07843138]\n",
      "   [0.33333334 0.2509804  0.6745098 ]\n",
      "   [0.4431373  0.90196085 0.01568628]\n",
      "   ...\n",
      "   [0.07450981 0.61960787 0.74509805]\n",
      "   [0.5254902  0.72156864 0.9215687 ]\n",
      "   [0.32941177 0.1764706  0.20784315]]\n",
      "\n",
      "  [[0.7294118  0.16862746 0.47058827]\n",
      "   [0.67058825 0.64705884 0.07450981]\n",
      "   [0.37254903 0.         0.6509804 ]\n",
      "   ...\n",
      "   [0.09411766 0.28627452 0.3137255 ]\n",
      "   [0.8117648  0.07058824 0.9607844 ]\n",
      "   [0.97647065 0.6392157  0.89019614]]\n",
      "\n",
      "  [[0.70980394 0.72156864 0.3529412 ]\n",
      "   [0.9490197  0.6313726  0.7490196 ]\n",
      "   [0.00392157 0.0509804  0.69411767]\n",
      "   ...\n",
      "   [0.13333334 0.5568628  0.00392157]\n",
      "   [0.23529413 0.19215688 0.9960785 ]\n",
      "   [0.26666668 0.20000002 0.04705883]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.9333334  0.14117648 0.68235296]\n",
      "   [0.39607847 0.9490197  0.21960786]\n",
      "   [0.8745099  0.12941177 0.8352942 ]\n",
      "   ...\n",
      "   [0.22352943 0.9176471  0.4666667 ]\n",
      "   [0.46274513 0.28235295 0.8980393 ]\n",
      "   [0.29803923 0.01568628 0.92549026]]\n",
      "\n",
      "  [[0.3019608  0.7294118  0.53333336]\n",
      "   [0.2627451  0.3019608  0.427451  ]\n",
      "   [0.7960785  0.7137255  0.13333334]\n",
      "   ...\n",
      "   [0.62352943 0.10980393 0.97647065]\n",
      "   [0.7725491  0.4901961  0.6666667 ]\n",
      "   [0.06666667 0.8588236  0.8117648 ]]\n",
      "\n",
      "  [[0.01960784 0.54901963 0.04705883]\n",
      "   [0.8862746  0.45882356 0.7843138 ]\n",
      "   [0.5411765  0.63529414 0.57254905]\n",
      "   ...\n",
      "   [0.70980394 0.27450982 0.6901961 ]\n",
      "   [0.6901961  0.75294125 0.29411766]\n",
      "   [0.8470589  0.07058824 0.54509807]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3137255  0.23529413 0.5137255 ]\n",
      "   [0.         0.9333334  0.12941177]\n",
      "   [0.882353   0.7607844  0.6313726 ]\n",
      "   ...\n",
      "   [0.72156864 0.5686275  0.89019614]\n",
      "   [0.9450981  0.7490196  0.48627454]\n",
      "   [0.23529413 0.45098042 0.45098042]]\n",
      "\n",
      "  [[0.6313726  0.63529414 0.92549026]\n",
      "   [0.9490197  0.77647066 0.65882355]\n",
      "   [0.10980393 0.63529414 0.01176471]\n",
      "   ...\n",
      "   [0.8431373  0.6901961  0.49803925]\n",
      "   [0.05882353 0.97647065 0.02352941]\n",
      "   [0.43921572 0.01176471 0.9843138 ]]\n",
      "\n",
      "  [[0.627451   0.8588236  0.2901961 ]\n",
      "   [0.427451   0.57254905 0.07058824]\n",
      "   [0.34901962 0.23529413 0.15294118]\n",
      "   ...\n",
      "   [0.5137255  0.50980395 0.01960784]\n",
      "   [0.28627452 0.3019608  0.43921572]\n",
      "   [0.43529415 0.7803922  0.54509807]]]\n",
      "\n",
      "\n",
      " [[[0.90196085 0.80392164 0.54901963]\n",
      "   [0.17254902 0.82745105 0.07843138]\n",
      "   [0.9725491  0.4901961  0.61960787]\n",
      "   ...\n",
      "   [0.882353   0.6627451  0.227451  ]\n",
      "   [0.4039216  0.92549026 0.7254902 ]\n",
      "   [0.38823533 0.         0.5647059 ]]\n",
      "\n",
      "  [[0.78823537 0.8470589  0.9921569 ]\n",
      "   [0.8705883  0.5254902  0.27058825]\n",
      "   [0.7294118  0.8862746  0.41176474]\n",
      "   ...\n",
      "   [0.30588236 0.7019608  0.86274517]\n",
      "   [0.30588236 0.26666668 0.70980394]\n",
      "   [0.5058824  0.4156863  0.20784315]]\n",
      "\n",
      "  [[0.64705884 0.50980395 0.73333335]\n",
      "   [0.12156864 0.29803923 0.20392159]\n",
      "   [0.70980394 0.48235297 0.7686275 ]\n",
      "   ...\n",
      "   [0.8000001  0.31764707 0.9333334 ]\n",
      "   [0.00392157 0.13333334 0.882353  ]\n",
      "   [0.24313727 0.30980393 0.9803922 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15686275 0.7019608  0.43137258]\n",
      "   [0.882353   0.8862746  0.65882355]\n",
      "   [0.41176474 0.2784314  0.9450981 ]\n",
      "   ...\n",
      "   [0.41176474 0.43921572 0.14117648]\n",
      "   [0.30980393 0.8980393  0.7607844 ]\n",
      "   [0.8000001  0.43137258 0.4431373 ]]\n",
      "\n",
      "  [[0.7254902  0.11764707 0.6431373 ]\n",
      "   [0.8431373  0.454902   0.52156866]\n",
      "   [0.5372549  0.01176471 0.91372555]\n",
      "   ...\n",
      "   [0.5764706  0.50980395 0.2392157 ]\n",
      "   [0.47450984 0.53333336 0.7254902 ]\n",
      "   [0.90196085 0.21176472 0.6313726 ]]\n",
      "\n",
      "  [[0.72156864 0.2901961  0.86666673]\n",
      "   [0.5372549  0.2627451  0.74509805]\n",
      "   [0.2784314  0.27058825 0.9921569 ]\n",
      "   ...\n",
      "   [0.69803923 0.47450984 0.9450981 ]\n",
      "   [0.21960786 0.5058824  0.36862746]\n",
      "   [0.26666668 0.69411767 0.7490196 ]]]\n",
      "\n",
      "\n",
      " [[[0.23529413 0.8078432  0.7058824 ]\n",
      "   [0.7137255  0.58431375 0.5686275 ]\n",
      "   [0.1137255  0.4901961  0.09411766]\n",
      "   ...\n",
      "   [0.93725497 0.7803922  0.01176471]\n",
      "   [0.7137255  0.34901962 0.8117648 ]\n",
      "   [0.52156866 0.43529415 0.72156864]]\n",
      "\n",
      "  [[0.70980394 0.93725497 0.6901961 ]\n",
      "   [0.60784316 0.7019608  0.11764707]\n",
      "   [0.10980393 0.02745098 0.5411765 ]\n",
      "   ...\n",
      "   [0.68235296 0.5254902  0.81568635]\n",
      "   [0.57254905 0.8352942  0.07843138]\n",
      "   [0.1764706  0.36862746 0.07450981]]\n",
      "\n",
      "  [[0.22352943 0.89019614 0.23137257]\n",
      "   [0.12941177 0.64705884 0.6156863 ]\n",
      "   [0.07450981 1.         0.44705886]\n",
      "   ...\n",
      "   [0.7372549  0.9921569  0.6509804 ]\n",
      "   [0.18823531 0.8862746  0.5058824 ]\n",
      "   [0.27058825 0.2509804  0.8470589 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3647059  0.09019608 0.3529412 ]\n",
      "   [0.7019608  0.09803922 0.36078432]\n",
      "   [0.18431373 0.32941177 0.53333336]\n",
      "   ...\n",
      "   [0.5294118  0.8078432  0.5294118 ]\n",
      "   [0.43921572 0.91372555 0.1137255 ]\n",
      "   [0.92549026 0.25882354 0.8745099 ]]\n",
      "\n",
      "  [[0.57254905 0.50980395 0.6156863 ]\n",
      "   [0.4039216  0.12156864 0.4156863 ]\n",
      "   [0.14117648 0.32941177 0.909804  ]\n",
      "   ...\n",
      "   [0.79215693 0.87843144 0.45098042]\n",
      "   [0.34509805 0.48235297 0.40000004]\n",
      "   [0.95294124 0.13333334 0.9490197 ]]\n",
      "\n",
      "  [[0.46274513 0.86666673 0.29411766]\n",
      "   [0.10980393 0.24705884 0.44705886]\n",
      "   [0.37254903 0.9843138  0.49411768]\n",
      "   ...\n",
      "   [0.49803925 0.5176471  0.43137258]\n",
      "   [0.654902   0.94117653 0.6156863 ]\n",
      "   [0.         0.5529412  0.4784314 ]]]], shape=(20, 32, 32, 3), dtype=float32)\n",
      "(20, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# 重新缩放和中心剪裁图像\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "train_data = np.random.randint(low=0, high=256, size=(20, 64, 64, 3))\n",
    "train_data = train_data.astype(np.float64)\n",
    "print(train_data)\n",
    "\n",
    "cropper = CenterCrop(height=32, width=32)  # 即在中心不变的情况下，剪裁至指定大小\n",
    "scaler = Rescaling(scale=1.0 / 255)  #即对图像张量进行标准化\n",
    "\n",
    "output_data = scaler(cropper(train_data))\n",
    "print(output_data)\n",
    "print(output_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.8268564e-12 4.2995194e-10 9.5498678e-12 4.4725705e-27 4.7587763e-19\n",
      "  1.6237056e-05 3.6863578e-26 4.5603317e-27 9.9997985e-01 3.9413389e-06]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# 模型可以看作是更大的层\n",
    "input_ = keras.Input(shape=(10, 20, 20, 3),\n",
    "                     name='input',\n",
    "                     dtype='int32')\n",
    "x = keras.layers.experimental.preprocessing.Normalization(axis=-1)(input_)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
    "                        padding='same', strides=2)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "output = keras.layers.Dense(units=10, activation='softmax', use_bias=0, name='out_')(x)\n",
    "model = keras.models.Model(inputs=input_, outputs=output)\n",
    "\n",
    "data = np.random.randint(low=0, high=256, size=(10, 20, 20, 3))\n",
    "data = data.astype(np.float64)\n",
    "\n",
    "out_data = model(data)\n",
    "print(out_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 多种训练的方式\n",
    "history = model.fit(x='input_data', y='output_label')\n",
    "history = model.fit(x='tf.Dataset, or generator')\n",
    "history = model.fit_generator('等价于fit的generator，这个端口实际上没必要使用了')\n",
    "\n",
    "# 还可以自己重写fit方法\n",
    "def train_step(self, data):\n",
    "    pass  # 详见文档"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 指标监控可以命名\n",
    "model.compile(metrics=[keras.metrics.MeanSquaredError(name='MSE')])\n",
    "\n",
    "# 使用tensorboard监控训练\n",
    "callbacks = [keras.callbacks.TensorBoard(log_dir='path')]\n",
    "model.fit(callbacks=callbacks)\n",
    "\n",
    "%tensorboard --logdir='path'  # 然后就可以查看了\n",
    "\n",
    "\n",
    "# 模型被编译成静态图一般来说，但难以调试，因为不是运行写出来的代码，于是可以使用动态来调试\n",
    "model.compile(run_eagerly=True)  # 高级功能，用得少\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}