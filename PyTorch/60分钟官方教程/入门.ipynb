{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000e-39, 4.2246e-39, 1.0286e-38],\n",
      "        [1.0653e-38, 1.0194e-38, 8.4490e-39],\n",
      "        [1.0469e-38, 9.3674e-39, 9.9184e-39],\n",
      "        [8.7245e-39, 9.2755e-39, 8.9082e-39],\n",
      "        [9.9184e-39, 8.4490e-39, 9.6429e-39]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个没有初始化的矩阵\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7447, 0.7026, 0.2485],\n",
      "        [0.0803, 0.8701, 0.6774],\n",
      "        [0.2839, 0.2333, 0.5424],\n",
      "        [0.4154, 0.9193, 0.9773],\n",
      "        [0.2222, 0.6770, 0.2769]])\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化矩阵\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 创造一个填满0且数据类型为long的矩阵\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.]], dtype=torch.float64)\n",
      "torch.Size([1, 2])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 直接根据数据构造\n",
    "x = torch.tensor([[1, 2]], dtype=torch.double)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "torch.float64\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[-0.6445,  0.5692,  0.0889],\n",
      "        [ 1.1806,  0.9119,  0.2063],\n",
      "        [ 1.8892, -0.9087, -1.6134],\n",
      "        [-0.9783, -0.1762, -0.8344],\n",
      "        [-0.6120, -2.0278, -0.3686]])\n"
     ]
    }
   ],
   "source": [
    "# 根据已有的tensor建立新tensor，默认继承原来，除非提供新值\n",
    "x = torch.empty(4, 3, dtype=torch.int)\n",
    "print(x)\n",
    "\n",
    "# 有好几种new_\n",
    "x = x.new_ones(3, 2, dtype=torch.double)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "x = x.new_zeros(5, 3, dtype=torch.int)\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 获取形状，本质上返回的是tuple，支持一切tuple的操作\n",
    "print(x.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 运算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2744,  0.9939,  0.5435],\n",
      "        [ 1.6934,  1.3109,  0.2401],\n",
      "        [ 1.9445, -0.6642, -1.3281],\n",
      "        [-0.0161,  0.6907, -0.5911],\n",
      "        [-0.5561, -1.8614,  0.1059]])\n",
      "tensor([[-0.2744,  0.9939,  0.5435],\n",
      "        [ 1.6934,  1.3109,  0.2401],\n",
      "        [ 1.9445, -0.6642, -1.3281],\n",
      "        [-0.0161,  0.6907, -0.5911],\n",
      "        [-0.5561, -1.8614,  0.1059]])\n",
      "tensor([[-0.2744,  0.9939,  0.5435],\n",
      "        [ 1.6934,  1.3109,  0.2401],\n",
      "        [ 1.9445, -0.6642, -1.3281],\n",
      "        [-0.0161,  0.6907, -0.5911],\n",
      "        [-0.5561, -1.8614,  0.1059]])\n",
      "tensor([[-0.2744,  0.9939,  0.5435],\n",
      "        [ 1.6934,  1.3109,  0.2401],\n",
      "        [ 1.9445, -0.6642, -1.3281],\n",
      "        [-0.0161,  0.6907, -0.5911],\n",
      "        [-0.5561, -1.8614,  0.1059]])\n"
     ]
    }
   ],
   "source": [
    "# 加法\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "print(torch.add(x, y))\n",
    "\n",
    "# 将结果输出到某个张量\n",
    "result = torch.empty(x.shape)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# 原地操作的加法\n",
    "y.add_(x)  # 任何一个原地（in-place）操作后面都跟有下划线\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1806,  1.8892, -0.9783, -0.6120])\n"
     ]
    }
   ],
   "source": [
    "# 索引操作和标准numpy一样\n",
    "print(x[1:, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 改变形状，可以用view\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), z.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7770])\n",
      "0.7770328521728516\n"
     ]
    }
   ],
   "source": [
    "# 只有一个元素 可以用item得到数值\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 将torch的tensor转化为numpy(不支持charTensor的转化）\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35., 35., 35., 35., 35.])\n",
      "[35. 35. 35. 35. 35.]\n"
     ]
    }
   ],
   "source": [
    "# numpy改变数值\n",
    "a.add_(34)\n",
    "print(a)\n",
    "print(b)\n",
    "# b实际是和a共享一个数据的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11. 11. 11. 11. 11.]\n",
      "tensor([11., 11., 11., 11., 11.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 将numpy转化为tensor\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(shape=(5, ))\n",
    "b = torch.from_numpy(a)\n",
    "# a = a + 10  # 如果这样加，会导致不再共享数据\n",
    "np.add(a, 10, out=a)  # 这将会输出到原来的地址，保持共享\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7770], device='cuda:0')\n",
      "tensor([1.7770], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用.to将任何张量移动到GPU上\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  # CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建张量\n",
    "    x = x.to(device=device)  # 或者后期移动上去\n",
    "    z = x + y  # 此时z自动会存在GPU上\n",
    "    print(z)\n",
    "    print(z.to(device='cpu', dtype=torch.double))  # 移动回cpu，移动时可以改变类型\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}